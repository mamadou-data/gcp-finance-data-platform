# GCP Finance Data Platform  
### Architecture Medallion Serverless â€“ BigQuery & Cloud Scheduler

---

## ğŸ“– Contexte

Ce projet met en Å“uvre une Data Platform complÃ¨te sur Google Cloud Platform (GCP) en utilisant une architecture Medallion (Bronze / Silver / Gold) appliquÃ©e Ã  un dataset de transactions financiÃ¨res (PaySim).

Lâ€™objectif est de dÃ©montrer des pratiques industrielles de Data Engineering :

- Ingestion dans un Data Lake (GCS)
- ModÃ©lisation Data Warehouse (BigQuery)
- ImplÃ©mentation dâ€™un modÃ¨le en Ã©toile
- Optimisation via partitionnement et clustering
- Mise en place dâ€™une couche Data Quality
- Journalisation des exÃ©cutions (audit logging)
- Orchestration automatisÃ©e via Cloud Scheduler
- Pipeline pilotÃ© par Stored Procedure

---
 
## ğŸ—ï¸ Architecture globale
```
Cloud Scheduler
      â†“
BigQuery Stored Procedure
      â†“
Bronze (GCS â€“ Raw Data)
      â†“
Silver (Nettoyage & transformations)
      â†“
Gold (Star Schema)
      â†“
Data Quality & Audit Logging
```

Architecture 100% serverless (pas de cluster permanent).

---

## ğŸ¥‰ Bronze Layer â€“ Data Lake

- Stockage des donnÃ©es brutes dans Google Cloud Storage
- Zone dâ€™ingestion immuable
- SÃ©paration stricte stockage / transformation

Choix technique :
- GCS pour la scalabilitÃ©
- Faible coÃ»t de stockage

---

## ğŸ¥ˆ Silver Layer â€“ Data Preparation

Transformations effectuÃ©es via BigQuery :

- Conversion temporelle (`step â†’ transaction_datetime`)
- Filtrage des anomalies (`amount > 0`)
- Normalisation des types
- PrÃ©paration des donnÃ©es mÃ©tier

Objectif :
SÃ©parer les donnÃ©es techniques des donnÃ©es analytiques.

---

## ğŸ¥‡ Gold Layer â€“ Data Warehouse

ImplÃ©mentation dâ€™un modÃ¨le en Ã©toile :

### Tables de faits
- `fact_transactions`

### Dimensions
- `dim_transaction_type`
- `dim_date`

Optimisations :

- Partitionnement par date
- Clustering par type_id
- RequÃªtes analytiques optimisÃ©es

---

## ğŸ§ª Data Quality Layer

ContrÃ´les intÃ©grÃ©s au pipeline :

- CohÃ©rence du nombre de lignes
- VÃ©rification des valeurs nulles
- ContrÃ´le du taux de fraude
- Validation des volumes

RÃ©sultats stockÃ©s dans :
- `data_quality_audit`
- `pipeline_runs`

Approche :
Fail-fast logique intÃ©grÃ©e dans la procÃ©dure.

---

## âš™ï¸ Orchestration Serverless

Orchestration via :

- Cloud Scheduler
- Appel HTTP vers lâ€™API BigQuery
- ExÃ©cution dâ€™une Stored Procedure unique

Pourquoi ce choix ?

- Pas de cluster GKE
- Pas de maintenance dâ€™Airflow
- CoÃ»t rÃ©duit
- Architecture simplifiÃ©e
- Approche cloud-native

---

## ğŸ“Š Monitoring & Audit

Chaque exÃ©cution gÃ©nÃ¨re :

- run_id unique
- start_time
- end_time
- status (SUCCESS / FAILED)
- message

Permet :

- TraÃ§abilitÃ©
- AuditabilitÃ©
- Supervision du pipeline

---

## ğŸ› ï¸ Stack Technique

- Google Cloud Storage
- BigQuery
- Cloud Scheduler
- SQL
- Architecture Medallion
- ModÃ©lisation en Ã©toile
- Serverless orchestration

---

## ğŸ’¡ DÃ©cisions dâ€™architecture

| Sujet | Choix | Justification |
|--------|--------|--------------|
| Orchestration | Cloud Scheduler | Plus lÃ©ger que Composer |
| Transformations | BigQuery SQL | Serverless & scalable |
| Stockage brut | GCS | SÃ©paration stockage/compute |
| ModÃ©lisation | Star Schema | OptimisÃ© pour lâ€™analytique |
| Monitoring | Audit table | ObservabilitÃ© intÃ©grÃ©e |

---

## ğŸš€ AmÃ©liorations futures

- Gestion avancÃ©e des erreurs
- Alerting automatique en cas dâ€™Ã©chec
- Infrastructure as Code (Terraform)
- Monitoring via Cloud Monitoring
- IntÃ©gration CI/CD

---

## ğŸ¯ CompÃ©tences dÃ©montrÃ©es

- Data Architecture
- Cloud Data Engineering
- BigQuery optimization
- SQL avancÃ©
- Orchestration serverless
- Data Quality design
- Audit logging
